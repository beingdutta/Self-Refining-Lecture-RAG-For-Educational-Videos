{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb248bf-4a7b-4878-8a6c-da4252c0073b",
   "metadata": {},
   "source": [
    "Ref: https://github.com/X-PLUG/mPLUG-Owl/tree/main/mPLUG-Owl3\n",
    "\n",
    "Run this in vid_env environment. This models works with transformers ver 4.37.2 to 4.47.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d8350-520d-4550-9e7b-7654a54607ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d54f2-ec2b-47a3-948b-498f9e991cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"CONDA_DEFAULT_ENV\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fcb3f-7d57-42df-b9f5-d86c7fc8b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6baf553-5938-4f4e-9ed3-026dc3e67472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel\n",
    "from transformers import AutoTokenizer, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156d4d7-dd45-4e8d-b612-5a177dcbc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from decord import VideoReader, cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377654b9-27ac-4277-a83c-2493471b3e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "450c6ddf-ffb6-429f-99bc-04f19f970aa9",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46923d-70d0-4572-97e8-68d2353811ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'mPLUG/mPLUG-Owl3-7B-240728'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202e5a9-21f6-4a37-a754-5bf64f0e62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_path, \n",
    "    torch_dtype=torch.half, \n",
    "    trust_remote_code=True, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "processor = model.init_processor(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9706c15-8fe2-4e23-adb5-960161751e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00a12a-8050-4496-83a7-731073389a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671ef4a-4b15-4360-8a9c-1d53a78f80a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5aa6c-3e4d-446e-8dbd-1bdd73cbd696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d503879-9708-4329-91d1-1ece0ebdfd35",
   "metadata": {},
   "source": [
    "### Variable System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692dfd11-ab72-4a1a-8f36-cd96f135fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_prompt = (\n",
    "    \"You are a vision-language model answering questions about lecture videos. \"\n",
    "    \"You are given:\\n\"\n",
    "    \"1. A question\\n\"\n",
    "    \"2. The video frames themselves\\n\\n\"\n",
    "    \"Answer the question using ONLY the clearly visible visual evidence. \"\n",
    "    \"If the answer cannot be determined, say exactly: \"\n",
    "    \"\\\"The answer cannot be determined from the video.\\\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb806ec-5500-408a-b3f2-c1e5e0ba1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_prompt = (\n",
    "    \"You are reviewing an answer generated by a vision-language model.\\n\\n\"\n",
    "    \"Your task:\\n\"\n",
    "    \"1. Check whether the answer is STRICTLY grounded in the provided visible visual evidence.\\n\"\n",
    "    \"2. Do NOT use outside knowledge.\\n\"\n",
    "    \"3. Identify specific unsupported claims if present.\\n\\n\"\n",
    "    \"Respond in the following format:\\n\\n\"\n",
    "    \"[GROUNDING_CHECK]\\n\"\n",
    "    \"Grounded: YES or NO\\n\\n\"\n",
    "    \"[FEEDBACK]\\n\"\n",
    "    \"If NO:\\n\"\n",
    "    \"- Explain precisely which parts are not supported by the evidence.\\n\"\n",
    "    \"If YES:\\n\"\n",
    "    \"- Say \\\"The answer is fully grounded.\\\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0bdd0-d8cf-4e19-add8-0def4616ae67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2ac1a-93ac-415b-a4d0-397f675bd560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"You are a vision-language model analyzing lecture videos. \"\n",
    "# \"You must rely strictly on visual evidence from the video frames.\\n\\n\"\n",
    "# \"Follow these steps:\\n\"\n",
    "# \"1. Carefully examine the video frames.\\n\"\n",
    "# \"2. Perform OCR on any readable text appearing on slides, blackboards, or written material.\\n\"\n",
    "# \"3. Explicitly list the extracted text before reasoning.\\n\"\n",
    "# \"4. Answer the question using ONLY the extracted visual information.\\n\"\n",
    "# \"5. If the required information is not visible or readable, say \"\n",
    "# \"\\\"The answer cannot be determined from the video.\\\" Do NOT guess.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023c4d8-94a4-4aa9-9838-9c659b47ca39",
   "metadata": {},
   "source": [
    "### Prepare Chat Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d762ba-6097-4e73-8dc3-dc1852981919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_message(system_prompt, user_prompt):\n",
    "\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"<|video|> {user_prompt}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    ]\n",
    "    return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4023e1-fa76-4cef-88ed-cb55d3bc6525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e29b5580-fb69-4412-be27-23699009eac5",
   "metadata": {},
   "source": [
    "### Hallucinative Questions for Random Test:\n",
    "\n",
    "From chemistry.mp4\n",
    "\n",
    "question = 'What was the capacity of the beaker they used in the experiment?'\n",
    "\n",
    "question = 'What was the melting pointed shown in the experiment?'\n",
    "\n",
    "question = 'Did they use Potassium chlorate in the experiment?'\n",
    "\n",
    "question = 'Did they use water in the whole experiment?'\n",
    "\n",
    "question = 'What are the compounds being used here, list them'\n",
    "\n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "From insertion_sort.mp4\n",
    "\n",
    "question = 'Which sorting algorithm is being performed in the video?'\n",
    "\n",
    "question = 'How many element is present in the array shown ?'\n",
    "\n",
    "question = 'What is the runtime of the algorithm as explained by the professor?'\n",
    "\n",
    "question = 'Write the elements present in the array the professor is explaining?'\n",
    "\n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "From: 4min-video.mp4\n",
    "\n",
    "question = 'Who are the target audience of this course as per the slides shown in the video?'\n",
    "\n",
    "question = 'How many disciplines does electrical engineering overlaps with as shown in the slides in the video'\n",
    "\n",
    "question = 'The course is divided into how many modules?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b7040-c47d-4758-acab-5b47e2c66659",
   "metadata": {},
   "source": [
    "### Load Test Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66c3fb-ef6a-4226-886e-36c772d7c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = ['/home/aritrad/MSR-Project/random/insertion_sort.mp4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b520d-2a4d-4a2b-bf7c-6d61847d6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_FRAMES=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bffb4ae-04a7-47b0-b282-194f9f59ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_video(video_path):\n",
    "    \n",
    "    def uniform_sample(l, n):\n",
    "        gap = len(l) / n\n",
    "        idxs = [int(i * gap + gap / 2) for i in range(n)]\n",
    "        return [l[i] for i in idxs]\n",
    "\n",
    "    vr = VideoReader(video_path, ctx=cpu(0))\n",
    "    sample_fps = round(vr.get_avg_fps() / 1)  # FPS\n",
    "    frame_idx = [i for i in range(0, len(vr), sample_fps)]\n",
    "    if len(frame_idx) > MAX_NUM_FRAMES:\n",
    "        frame_idx = uniform_sample(frame_idx, MAX_NUM_FRAMES)\n",
    "    frames = vr.get_batch(frame_idx).asnumpy()\n",
    "    frames = [Image.fromarray(v.astype('uint8')) for v in frames]\n",
    "    #print(frames)\n",
    "    print('num frames:', len(frames))\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13998d2f-7018-4fac-84c9-6c0710925043",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = [encode_video(_) for _ in videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ade61-5e23-4a47-b68e-b5b51783f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames[0][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2cc40-5ef0-4f7e-afa0-bd0ef79951b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66c6b445-f6f3-4b4d-808f-65e6f6daadb5",
   "metadata": {},
   "source": [
    "### Generate Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eaa39d-1e6c-4dc6-abcf-4bdc2c310a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What algorithm is the professor explaining in the video?'\n",
    "message = create_chat_message(generation_prompt, question)\n",
    "inputs = processor(message, images=None, videos=video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba02c9-7041-4f47-a858-f7539f293b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.to('cuda')\n",
    "inputs.update({\n",
    "    'tokenizer': tokenizer,\n",
    "    'max_new_tokens':512,\n",
    "    'decode_text':True,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749e050-7582-4749-950a-8d4d74cfa6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "answer = model.generate(**inputs)\n",
    "print(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc312d-457e-4273-8a46-2885a9123a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95ecee7c-a137-4a65-9577-d7b305455b43",
   "metadata": {},
   "source": [
    "### Generate Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8dddbb-fc57-4cf6-bddc-1da8683f4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_question = f'Given Question: {question}, Generated Answer: {answer[0]}'\n",
    "fb_message = create_chat_message(feedback_prompt, fb_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ec0ca-c07b-4abe-9fd0-57402866b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(fb_message, images=None, videos=video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5c568-80c0-47c6-b9ac-0353a040cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.to('cuda')\n",
    "inputs.update({\n",
    "    'tokenizer': tokenizer,\n",
    "    'max_new_tokens':512,\n",
    "    'decode_text':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f677b-9bee-452a-9424-8d268ad86496",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "answer = model.generate(**inputs)\n",
    "print(answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636a66b-0631-4367-8875-39c8eb20dc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
